---
title: "PREP_imaging_R4.0"
author: "Niamh MacSweeney & Nikolaj Høier. 
date: "21/03/2022"
output: github_document
---
For any questions, please email: [niamh.macsweeney\@ed.ac.uk](mailto:niamh.macsweeney@ed.ac.uk){.email} or Nikolaj Høier ([2250502\@ed.ac.uk](mailto:2250502@ed.ac.uk){.email})

#### Introduction

The purpose of this script is to quality control and process the ABCD imaging data (cortical, diffusion/white matter, subcortical) using data from Release 4.0.

##Helpful Documents:

Follow the QC criteria recommended by ABCD in NDA release 4.0 Imaging Instrument Release Notes:

NDA 4.0 MRI Quality Control Recommended Inclusion (please read for full details)

In brief, here is the criteria we will use: 
For the T1w data: imgincl_t1w_include = 1 indicates that the T1w series meets all the criteria for inclusion.
For dMRI (DTI/RSI): imgincl_dmri_include = 1 indicates that the dMRI series meets all the criteria for inclusion. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

####SETUP Load libraries needed and set working directory.

USER: change working directory as needed.

```{r, setup}

library(tidyverse)
library(dplyr)
library(broom)
library(ggplot2)
library(kableExtra)
library(readxl)
library(corrplot)

setwd("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/prep")

```

For reference, here is an Excel spread sheet of the cortical, subcortical, and white matter tracts included in ABCD based on FreeSurfer and TractAtlas parcellation. This is a useful document for making sense of the abbreviations provided in the ABCD imaging files. 

```{r, load in Excel spreadsheet with abbreviations and descriptions for brain regions}

brain_region_description <- read_excel("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/prep/brain_measures_descriptions.xlsx")

```
##STEP 1: LOAD DATA FOR QUALITY CONTROL AND SELECT VALID IDS

##USER: Adjust filter accordingly depending on your timepoint of interest (e.g., baseline, year 2 etc.)

For the purposes of this project, we are interested in Year 0 (baseline) and Year 2 (Two-year followup) Imaging data:

variable names: "baseline_year_1\_arm_1" and "2_year_follow_up_y\_arm_1"

Need satisfactory T1 raw images and DTI QC. Baseline and Year 2 will be run separately.

Note: Approximately 87% of participants completed year 2 neuroimaging due Covid-19 related data collection disruption.

See protocol notes: <https://abcdstudy.org/scientists/protocols>

```{r, load data and tidy}

qc_imgincl <-readRDS("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_QC/abcd_imgincl01.rds")

qc_imgincl$eventname <- as.factor(qc_imgincl$eventname) #check variable levels (needs to be in factor format)
levels(qc_imgincl$eventname)

#Check how sample sizes for each wave of imaging data. 
img_sample_siz_tbl <- qc_imgincl %>%
  group_by(eventname) %>% 
  summarise(no_rows = length(eventname))
print(img_sample_siz_tbl)

#Make separate dataframes for Baseline and Year 2

#Baseline (year 0) N= 11,801
qc_imgincl_y0 <- qc_imgincl %>% 
  filter(eventname == "baseline_year_1_arm_1") #reduce to year 0 data only, 

#Year 2 N= 7,857
qc_imgincl_y2 <- qc_imgincl %>% 
  filter(eventname == "2_year_follow_up_y_arm_1") 
```

Select IDs that passed QC for T1 (cortical and subcortical) and DTI

Field name: imgincl_t1w_include = T1: Number of series that are complete and passed QC. Valid IDs: =="yes"

Field name: imgincl_dmri_include = DTI: Number of series that are complete and passed QC. Valid IDs: =="yes"

```{r, valid IDs}

#here we simply create new values i.e. t1.ids.pass - if a subject id fulfills the criteria, it will pass into this new value. 

### Baseline ###

#T1 valid IDs
t1_ids_pass_y0 <- qc_imgincl_y0 %>% 
  select(src_subject_id, imgincl_t1w_include) %>%  
  filter(imgincl_t1w_include == "Yes") 
t1_ids_pass_y0 <- t1_ids_pass_y0$src_subject_id # make new column for valid t1 IDs --- N = 11,401

# DTI valid IDs
dti_ids_pass_y0 <- qc_imgincl_y0 %>% 
  select(src_subject_id,imgincl_dmri_include) %>% 
  filter(imgincl_dmri_include == "Yes")
dti_ids_pass_y0 <- dti_ids_pass_y0$src_subject_id #make new column for valid DTI IDs ---- N = 10,406


###Year 2 ###
# T1 valid IDs
t1_ids_pass_y2<- qc_imgincl_y2 %>% 
  select(src_subject_id, imgincl_t1w_include) %>%  
  filter(imgincl_t1w_include == "Yes") 
t1_ids_pass_y2 <- t1_ids_pass_y2$src_subject_id # make new column for valid t1 IDs --- N = 7,695


# DTI valid IDs
dti_ids_pass_y2 <- qc_imgincl_y2 %>% 
  select(src_subject_id,imgincl_dmri_include) %>% 
  filter(imgincl_dmri_include == "Yes")
dti_ids_pass_y2 <- dti_ids_pass_y2$src_subject_id #make new column for valid DTI IDs ---- N = 7,315

```

#STEP 2: PROCESS IMAGING DATA

#### Cortical Measures

Using cortical volume, surface area, thickness and sulcal depth.

```{r, load T1 structural measures (cortical,subcortical) data}
t1 <- rio::import("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_T_roi/abcd_smrip10201.rds")

```

Rename columns to make more intuitive/easier to read

Note: APARC = cortical parcellation in Free Surfer syntax

```{r, rename columns}

colnames(t1)=gsub('smri_','',colnames(t1))
colnames(t1)=gsub('_cdk_','.APARC.',colnames(t1)) 
colnames(t1)=gsub('_scs_','.ASEG.',colnames(t1)) 
colnames(t1)=gsub('thick.','thk.',colnames(t1))
colnames(t1)=gsub('area.','sa.',colnames(t1))

```

\#Whole Brain Volume\#

We will use wholebrain volume (WBV) as a covariate in our regional measure models but not in our global measure models. ABCD have derived a measure of WBV that we will use but we will rename it to just "WBV". 

We are choosing to use WBV instead of intracranial volume to account for differences in overall brain size. According to previous research (e.g., Mills et al., 2016, https://www.sciencedirect.com/science/article/pii/S1053811916303512?via%3Dihub#bb0190), ICV and WBV demonstrate different growth trajectories and should not be used interchangeably. Further, WBV may be a more appropriate measure to use in developmental samples.  

```{r, change WBV and ICV variable name}

t1 <- t1 %>% 
  dplyr::rename(WBV = vol.ASEG.wholeb)

t1 <- t1 %>% 
   dplyr::rename(ICV = vol.ASEG.intracranialv)
         

```

Rearrange col names so that hemisphere (lh or rh or bl (bilateral) is indicated as the start of col name

```{r, further renaming}

colnames(t1)[grep('lh$',colnames(t1))]=paste0('lh.',gsub('lh$','',colnames(t1)))[grep('lh$',colnames(t1))]
colnames(t1)[grep('rh$',colnames(t1))]=paste0('rh.',gsub('rh$','',colnames(t1)))[grep('rh$',colnames(t1))]
colnames(t1)[grep('^vol.|^sa.|^sulc.|^thk.',colnames(t1))]=paste0('bl.',colnames(t1))[grep('^vol.|^sa.|^sulc.|^thk.',colnames(t1))]

colnames(t1) #check it worked - looks like there is an issue with the accumbens area (subcortical measure) so rename manually

t1 <- t1 %>% 
  rename(rh.vol.ASEG.aa = bl.vol.ASEG.aar,
         lh.vol.ASEG.aa = bl.vol.ASEG.aal) #rename right aa

```

We will remove total and mean measures for each hemisphere (i.e., rh and lh) as we are not interested in these for the purposes of the present analysis.

This will leave us with cortical metrics (vol, sa, sulcal depth and thickness) for individual regions.

```{r, remove total and mean hemisphere measures}

cols_omit <-  t1 %>% .[grep(c("^rh.+\\.total$|^lh.+\\.total$|^rh.+\\.mean$|^lh.+\\.mean$"),colnames(.))] 
t1 <- t1[,!colnames(t1) %in% colnames(cols_omit)]

```

Generate separate dataframes for Baseline and Year 2 and extract variables of interest
Note: we are selecting our imaging columns that contain "APARC" as these are the Freesurfer derived metrics we are using. 
```{r, generate df and extract vars of interest}
### Baseline ###
cortical_y0 <- t1 %>% 
  filter(eventname == "baseline_year_1_arm_1") %>% #reduce to baseline; N= 11760
  select("src_subject_id", contains("APARC"), "WBV", "ICV") #selecting cols contains "APARC" = 278 variables in df and also WBV
   

### Year 2 ###
cortical_y2 <- t1 %>%  
  filter(eventname == "2_year_follow_up_y_arm_1") %>% #reduce to Year 2 only --- N= 7827
  select("src_subject_id", contains("APARC"), "WBV", "ICV") #select cols containing "APARC" = 278 vars

```

Before generating average measures, we need to get the data in the correct format so that the lh and rh measure for each brain structure for each metric are side by side in dataframe. 

This is not the most sophisticated approach.

1. Generate seperate dataframe for each metric (e.g., sa, vol, thk, sulc)
2. Sort based on substring
3. Sort alphabetically by brain measure name (this should place lh and rh side by side for each brain measure)
4. Re-name again so that lh and rh is at the start of variable name (for the purposes of the script and function set up)
5. Repeat for each metric and then merge to create one df. 

```{r, reorder data per metric type}

####thickness
thk <- cortical_y0 %>%  #extract thk vars only
  select(contains("thk")) 

m = names(thk)  # Extract column names.

r = strsplit(m,".thk.APARC.") # Split the column names based on the ".thk.APARC."

# Create a data.frame with two columns X1 being lh or rh
# X2 being brain structure name (e.g., bankssts, cdacate, cdmdfr etc.)
q = data.frame(matrix(unlist(r),nrow=length(m),byrow=T)) 

# Order q according to spec
q = q[order(q$X2,q$X1, decreasing = F),]

# Reformat names
m = paste0(q$X1,".thk.APARC.",q$X2)

# Rearrange columns
thk = thk[,m]

#check it worked
colnames(thk)

####sulcal depth

sulc <- cortical_y0 %>% 
  select(contains("sulc")) 

m = names(sulc)  # Extract column names.

r = strsplit(m,".sulc.APARC.") # Split the column names based on the ".sulc.APARC."

# Create a data.frame with two columns X1 being lh or rh
# X2 being brain structure name (e.g., bankssts, cdacate, cdmdfr etc.)
q = data.frame(matrix(unlist(r),nrow=length(m),byrow=T)) 

# Order q according to spec
q = q[order(q$X2,q$X1, decreasing = F),]

# Reformat names
m = paste0(q$X1,".sulc.APARC.",q$X2)

# Rearrange columns
sulc = sulc[,m]

colnames(sulc) #check it worked. 


######surface area

sa <- cortical_y0 %>% 
  select(contains("sa")) 

m = names(sa)  # Extract column names.

r = strsplit(m,".sa.APARC.") # Split the column names based on the ".sa.APARC."

# Create a data.frame with two columns X1 being lh or rh
# X2 being brain structure name (e.g., bankssts, cdacate, cdmdfr etc.)
q = data.frame(matrix(unlist(r),nrow=length(m),byrow=T)) 

# Order q according to spec
q = q[order(q$X2,q$X1, decreasing = F),]

# Reformat names
m = paste0(q$X1,".sa.APARC.",q$X2)

# Rearrange columns
sa = sa[,m]

colnames(sa) #check it worked

######volume

vol <- cortical_y0 %>% 
  select(contains("vol")) 

m = names(vol)  # Extract column names.

r = strsplit(m,".vol.APARC.") # Split the column names based on the ".vol.APARC."

# Create a data.frame with two columns X1 being lh or rh
# X2 being brain structure name (e.g., bankssts, cdacate, cdmdfr etc.)
q = data.frame(matrix(unlist(r),nrow=length(m),byrow=T)) 

# Order q according to spec (i.e, alpahbetical order of brain measures)
q = q[order(q$X2,q$X1, decreasing = F),]

# Reformat names
m = paste0(q$X1,".vol.APARC.",q$X2)

# Rearrange columns
vol = vol[,m]

colnames(vol) #check it worked

#### Extract src_subject_id, WBV and ICV and save as new df (so that final merged dataframe contains the same vars as cortical_y0 just reordered)

remaining_vars <- cortical_y0 %>% 
  select("src_subject_id", "WBV", "ICV")

#####join dataframes together 

new_order <- cbind(remaining_vars, thk) %>% 
  cbind(sulc) %>% 
  cbind(sa) %>% 
  cbind(vol)
colnames(new_order) #join worked #should have 279 vars for 11760 rows, i.e., it should be identical to cortical_y0 

cortical_y0 <- new_order #replace old cortical df with new order df

```



```{r, generate average measure across hemispheres}

#generate list of all bilateral cortical measures by removing the unilateral cortical measures + WBV and ICV
cortical_bilateral_colnames <- names(cortical_y0)[! names(cortical_y0) %in% c("src_subject_id", "bl.vol.APARC.total", "bl.sa.APARC.total", "bl.thk.APARC.mean", "bl.sulc.APARC.mean","WBV", "ICV")] 


#make for loop that loops across each pair of measures
for (i in seq(1, length(cortical_bilateral_colnames), by=2)){


  ## Average right left hemisphere
  mean <- rowMeans(cortical_y0[,cortical_bilateral_colnames[c(i, i+ 1)]])
  cortical_bilateral_colnames[i]

  cortical_measure_name <- sub("rh.", "", cortical_bilateral_colnames[i])
  cortical_measure_name <- sub("lh.", "", cortical_measure_name)
  cortical_measure_name <- paste0("avg.", cortical_measure_name)

  ## Save averaged measures to new column
  cortical_y0[,paste0(cortical_measure_name)] <- mean

}

colnames(cortical_y0) #check that it worked

#double check that average measures were generate correctly 

mean_test1 <- cortical_y0 %>% #extract two cols and get average
  select(rh.sulc.APARC.sufr,lh.sulc.APARC.sufr) %>% 
  rowMeans()

mean_test1 == cortical_y0$avg.sulc.APARC.sufr #this should return TRUE for all variables - it does! 

#let's test with another variable just to be sure
mean_test2 <- cortical_y0 %>% #extract two cols and get average
  select(rh.sa.APARC.locc,lh.sa.APARC.locc) %>% 
  rowMeans()

mean_test2 == cortical_y0$avg.sa.APARC.locc#this should return TRUE for all variables - it does! 

```

Select IDs that passed QC check ---- N=11232

Note: If the above QC steps have run correctly, the final N you get here should equal the N for t1_ids_pass_y0 etc.

Note, average measures for Year 2 have not been generate yet! 

```{r, select QC'd IDs}

### Baseline ###

cortical_y0_final <- cortical_y0 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y0,]  #N = 11401
colnames(cortical_y0_final)


### year 2 ###
cortical_y2_final <- cortical_y2 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y2,] #N= 7695
colnames(cortical_y2_final) #check col names 

```

Check distribution for global (total) vol and sa. Looks normally distributed so all good!

```{r, check distribution vol and sa}

### Baseline ###
cortical_y0_final %>%
  select(contains(".total")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 15) #Looks fine. 

### Year 2 ###
cortical_y2_final %>%
  select(contains(".total")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 15) #Looks fine. 


```

Check distribution for global (mean) sulc and thk. Looks okay too!

```{r, check distribution sulc and thk, fig.show="hold", out.width="50%"}

### Baseline ###
cortical_y0_final %>%
  select(contains(".mean")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4", 
                 bins = 15) 

### Year 2 ###
cortical_y2_final %>%
  select(contains(".mean")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4", 
                 bins = 15) 

```

#### DTI/White matter Measures

Using fractional anisotropy and mean diffusivity as measures of white matter microstructure.

Note that we are using the inner shell DTI measures for this analysis (abcd_dti_p101.rds) instead of Full shell DTI measures (abcd_dmdtifp101.rds). Both measures are available in ABCD. We have conducted sensitivity analysis between the two measures and we found very similiar effects sizes across inner shell and full shell for DTI. 

There is some research suggesting that Full shell is more appropriate for developmental samples (e.g., https://www.sciencedirect.com/science/article/pii/S1878929320300360). However, given the results of the sensitivity analysis, for the present study (i.e., MacSweeney et al.'s RR), we will stick to inner shell. 

```{r, load DTI measures}
dti <- rio::import("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_T_roi/abcd_dti_p101.rds")

```

Tidy up column names

```{r, rename columns}

colnames(dti)[grep('\\.all&rh$',colnames(dti))]=
  paste0('rhtotal.',gsub('\\.all|rh$','',colnames(dti)))[grep('\\.all|rh$',colnames(dti))]

#rearrange col names as done for cortical measures to make reading easier. 
colnames(dti)[grep('lh$',colnames(dti))]=paste0('lh.',gsub('lh$','',colnames(dti)))[grep('lh$',colnames(dti))]
colnames(dti)[grep('rh$',colnames(dti))]=paste0('rh.',gsub('rh$','',colnames(dti)))[grep('rh$',colnames(dti))]
colnames(dti)[grep('\\_all',colnames(dti))]=paste0('bl.',colnames(dti))[grep('\\_all',colnames(dti))]
colnames(dti)[grep('^dti',colnames(dti))]=paste0('bl.',colnames(dti))[grep('^dti',colnames(dti))]

```


Here, we want to reduce the dataframes to our variables of interest. We want to keep all fa and md measures for our tracts of interest and exclude certain columns (detailed below) that are not relevant to our analysis. 

At this point we will generate separate dataframes for each timepoint (i.e., Baseline (Year 0) and Year 2)

```{r, reduce to variables of interest per timepoint}

### Baseline ###
dti_y0 <- dti %>% 
  filter(eventname == "baseline_year_1_arm_1") %>% 
  .[,grep("subject|_dtifa_|_dtimd_", colnames(.))] %>% #select FA and MD cols
  .[,grep('subject|fiberat',colnames(.))] #include DTI atlas tract adjustment #should have 85 variables 

#remove average FA and MD in tracts without corpus callosum (_allfcc) and the average longitudinal coefficient across all DTI tract fibers(_allfib)
cols.omit <- dti_y0 %>% .[grep("_allfcc$|_allfib$",colnames(.))] 
dti_y0 <- dti_y0[,!colnames(dti_y0) %in% colnames(cols.omit)] #should have 77 variables

#Tidy up column names
colnames(dti_y0)=gsub('dmri_','',colnames(dti_y0))
colnames(dti_y0)=gsub('fiberat_','',colnames(dti_y0))

### Year 2 ###
dti_y2 <- dti %>% 
  filter(eventname == "2_year_follow_up_y_arm_1") %>% 
  .[,grep("subject|_dtifa_|_dtimd_", colnames(.))] %>% #select FA and MD cols
  .[,grep('subject|fiberat',colnames(.))] #include DTI atlas tract adjustment #should have 85 variables 

#remove average FA and MD in tracts without corpus callosum (_allfcc) and the average longitudinal coefficient across all DTI tract fibers(_allfib)
cols.omit <- dti_y2 %>% .[grep("_allfcc$|_allfib$",colnames(.))] 
dti_y2 <- dti_y2[,!colnames(dti_y2) %in% colnames(cols.omit)] #should have 77 variables

#Tidy up column names
colnames(dti_y2)=gsub('dmri_','',colnames(dti_y2))
colnames(dti_y2)=gsub('fiberat_','',colnames(dti_y2))

```

#Generate average measure across two hemispheres. 

```{r, get average measure across two hemispheres for regional measures}

#### Baseline #####

dti_bilateral_colnames <- names(dti_y0)[! names(dti_y0) %in% c("src_subject_id", "bl.dtifa_allfibers", "bl.dtimd_allfibers","dtimd_fmaj", "dtimd_fmin", "dtimd_cc","dtifa_fmaj", "dtifa_fmin", "dtifa_cc" )]



for (i in seq(1, length(dti_bilateral_colnames), by=2)){


  ## Average right left hemisphere
  mean <- rowMeans(dti_y0[,dti_bilateral_colnames[c(i, i+ 1)]])
  dti_bilateral_colnames[i]

  DTI_tract_name <- sub("rh.", "", dti_bilateral_colnames[i])
  DTI_tract_name <- sub("lh.", "", DTI_tract_name)
  DTI_tract_name <- paste0("avg.", DTI_tract_name)

  ## Save averaged measures to new column
  dti_y0[,paste0(DTI_tract_name)] <- mean

}

colnames(dti_y0) #check that it worked

```


Select IDs that pass QC for each timepoint

```{r, select valid IDs}

### Baseline ###
dti_y0_final<- dti_y0 %>% 
  .[.$src_subject_id %in% dti_ids_pass_y0,] #N= 10,406

### year 2 ###
dti_y2_final<- dti_y2 %>% 
  .[.$src_subject_id %in% dti_ids_pass_y2,] #N= 7,315


```

Check distribution of FA and MD

The MD values do appear to be skewed. However, instead of removing outliers at this stage, we can conduct a sensitivity analysis at a later stage (if needed) to see if the outliers are affecting the associations. However, removing outliers ±5 SD does not seem to be the standard approach taken by other ABCD users. It is important to note that the ABCD team remove impossible values in advance of the curated data release and therefore, the extreme values are likely real.

```{r, check distribution, fig.show="hold", out.width="50%"}
###Baseline###
dti_y0_dist <- dti_y0_final %>%
  select(ends_with("allfibers"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) 
dti_y0_dist

###year 2###
dti_y2_dist <- dti_y2_final %>%
  select(ends_with("allfibers"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 30) 
dti_y2_dist
```

IGNORE for pilot analysis: Check for multicollinearity in DTI measures

```{r, check for mutlicollinearity}


# #check colinearity with dti variables only 
# dti_y0_corr <- dti_y0_final %>% 
#   dplyr::select(contains("dti"))
# 
# #issue only with regional measures so remove all fibers
# dti_y0_corr <- dti_y0_corr %>% 
#   dplyr::select(-(contains("allfibers")))
# 
# #make correlation matrix for fa and md measures separately 
# 
# fa_y0 <- dti_y0_corr %>% 
#     dplyr::select(contains("fa")) #37 variables (36 dti measures, 18 per hemisphere)
# 
# fa_y0_corr_mat = cor(fa_y0, method = "pearson", use = "pairwise.complete.obs")
# 
# (positions <- subset(as.data.frame(which(cor(fa_y0_corr_mat) > 0.99, arr.ind=TRUE)), row < col)) #seems to be multicolinearity issues. 
# 
# #visualise correlation matrix
# 
# corrplot(fa_y0_corr_mat, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 40)


```


####Subcortical volume measures (before QC, N =11,736)

We will select the subcortical regions that overlap with ENIGMA and add in the ventral diencephalon. Note that we are only looking at subcortical volume (not thicnkess, surface area or sulcal depth)

We have already renamed and tidied to T1 file above so we can load this in from our global environment and then select the subcortical variables and ICV. 
```{r, make subcortical df from t1}

subcort <- t1 

```

Create separate dataframes for Baseline and Year 2.

```{r, make DFs for baseline and year 2}

###Baseline####


subcort_y0 <- subcort %>% 
filter(eventname == "baseline_year_1_arm_1") %>%#reduce to baseline --- N = 11,760
.[,grep("subject|vol\\.ASEG|WBV|ICV", colnames(.))] %>%   #select smri vol data
.[,grep("subject|aa|amygdala|caudate|hpus|pallidum|putamen|tp|vedc|WBV|ICV",colnames(.))] #select relevant columns 


###Year 2 ####
subcort_y2 <- subcort %>% 
filter(eventname == "2_year_follow_up_y_arm_1") %>% #reduce to  --- N = 7827
.[,grep("subject|vol\\.ASEG|WBV|ICV", colnames(.))] %>%   #select smri vol data
.[,grep("subject|aa|amygdala|caudate|hpus|pallidum|putamen|tp|vedc|WBV|ICV",colnames(.))] #select relevant columns #should have 19 cols in df if worked correctly


```

###Generate average measure across two hemispheres for each bilateral measure

We will adopt same approach as the cortical measures where we will reorder the variables first into pairs 

Reorder variables 
```{r, reorder data per metric type}

####subcortical volume (only metric for subcortical measures)
subcort_new <- subcort_y0 %>%  #extract vol vars only (i.e., don't select id, WBV, ICV)
  select(contains("vol")) 

m = names(subcort_new)  # Extract column names.

r = strsplit(m,".vol.ASEG.") # Split the column names based on the ".vol.ASEG."

# Create a data.frame with two columns X1 being lh or rh
# X2 being brain structure name (e.g., bankssts, cdacate, cdmdfr etc.)
q = data.frame(matrix(unlist(r),nrow=length(m),byrow=T)) 

# Order q according to spec
q = q[order(q$X2,q$X1, decreasing = F),]

# Reformat names
m = paste0(q$X1,".vol.ASEG.",q$X2)

# Rearrange columns
subcort_new = subcort_new[,m]

#check it worked
colnames(subcort_new)

#add back in id, WBV and ICV
remaining_vars <- subcort_y0 %>% 
  select("src_subject_id", "WBV", "ICV")

#join dataframes 

all <- cbind(subcort_new, remaining_vars)
colnames(all) #check join worked - it did! 

subcort_y0 <- all #replace old subcort_y0 with reordered dataframe 
colnames(subcort_y0)

```
Generate average for subcortical measures

```{r, get average for subcortical measures}
#generate list of all bilateral cortical measures by removing the id + WBV and ICV
subcort_bilateral_colnames <- names(subcort_y0)[! names(subcort_y0) %in% c("src_subject_id", "WBV", "ICV")] 


#make for loop that loops across each pair of measures
for (i in seq(1, length(subcort_bilateral_colnames), by=2)){


  ## Average right left hemisphere
  mean <- rowMeans(subcort_y0[,subcort_bilateral_colnames[c(i, i+ 1)]])
  subcort_bilateral_colnames[i]

  subcort_measure_name <- sub("rh.", "", subcort_bilateral_colnames[i])
   subcort_measure_name <- sub("lh.", "", subcort_measure_name)
   subcort_measure_name <- paste0("avg.", subcort_measure_name)

  ## Save averaged measures to new column
  subcort_y0[,paste0(subcort_measure_name)] <- mean

}

colnames(subcort_y0) #check that it worked

#double check that average measures were generate correctly 

mean_test1 <- subcort_y0 %>% #extract two cols and get average
  select(lh.vol.ASEG.amygdala,rh.vol.ASEG.amygdala) %>% 
  rowMeans()

mean_test1 == subcort_y0$avg.vol.ASEG.amygdala #this should return TRUE for all variables - it does! 

#let's test with another variable just to be sure
mean_test2 <- subcort_y0 %>% #extract two cols and get average
  select(lh.vol.ASEG.caudate,rh.vol.ASEG.caudate) %>% 
  rowMeans()

mean_test2 == subcort_y0$avg.vol.ASEG.caudate#this should return TRUE for all variables - it does! 
```

Select IDs that passed QC, N=11,232

```{r, select valid IDs}

###Baseline####
subcort_y0_final <- subcort_y0 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y0,] #N= 11401


subcort_y2_final <- subcort_y2 %>% 
   .[.$src_subject_id %in% t1_ids_pass_y2,] #N= 7695


```

Check distribution of subcortical measures

```{r, check distribution, fig.show="hold", out.width="50%"}

###Baseline####
 subcort_y0_dist <- subcort_y0_final %>%
  select(!starts_with("src"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) #all look okay
subcort_y0_dist

###Year 2####
 subcort_y2_dist <- subcort_y2_final %>%
  select(!starts_with("src"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) #all look okay
 subcort_y2_dist
```
Let's look at the final variables for subcortical measures (17 in total, including lh and rh) after QC. Note: subcortical_gv = subcortical grey volume.




####Check for and remove duplicate or highly similar columns that may have occured due to earlier renaming.  

User can adapt as needed for the purposes of their own analysis. 

```{r, remove cols not needed}

###Baseline data ####
#check colnames
colnames(cortical_y0_final) #no duplicate cols. 
colnames(subcort_y0_final) 
colnames(dti_y0_final)

###Year 2 data ####
#check colnames
colnames(cortical_y2_final) #no duplicate cols. 
colnames(subcort_y2_final) 
colnames(dti_y2_final)

```


####EXPORT CLEANED DATA

USER: change as needed 

Change working directory and save clean file there. Note: clean files should be saved in data folder in ABCD_puberty_RR project folder.

```{r, export cleaned data}

setwd("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/data")

###Baseline data ####
saveRDS(cortical_y0_final,"cortical_baseline_R4.0.rds")
saveRDS(dti_y0_final,"dti_baseline_R4.0.rds")
saveRDS(subcort_y0_final,"subcort_baseline_R4.0.rds")
# 
# ###Year 2 data ####
saveRDS(cortical_y2_final,"cortical_year2_R4.0.rds")
saveRDS(dti_y2_final,"dti_year2_R4.0.rds")
saveRDS(subcort_y2_final,"subcort_year2_R4.0.rds")

```

\#\#\#\#------------ END OF MAIN SCRIPT -----------------\#\#\#\#
