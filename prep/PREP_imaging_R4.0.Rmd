---
title: "PREP_imaging_R4.0"
author: "Niamh MacSweeney & Nikolaj Høier. 
date: "21/03/2022"
output: html_document
---
For any questions, please email: [niamh.macsweeney\@ed.ac.uk](mailto:niamh.macsweeney@ed.ac.uk){.email} or Nikolaj Høier ([2250502\@ed.ac.uk](mailto:2250502@ed.ac.uk){.email})

#### Introduction

The purpose of this script is to quality control and process the ABCD imaging data (cortical, diffusion/white matter, subcortical) using data from Release 4.0.

\#Helpful Documents:

Follow the QC criteria recommended by ABCD in NDA release 4.0 Imaging Instrument Release Notes:

NDA 4.0 MRI Quality Control Recommended Inclusion (please read for full details)

In brief, here is the criteria we will use: 
For the T1w data: imgincl_t1w_include = 1 indicates that the T1w series meets all the criteria for inclusion.
For dMRI (DTI/RSI): imgincl_dmri_include = 1 indicates that the dMRI series meets all the criteria for inclusion. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

\#SETUP Load libraries needed and set working directory.

USER: change working directory as needed.

```{r, setup}

library(tidyverse)
library(dplyr)
library(broom)
library(ggplot2)
library(kableExtra)
library(readxl)

setwd("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/prep")

```

For reference, here is an Excel spread sheet of the cortical, subcortical, and white matter tracts included in ABCD based on FreeSurfer and TractAtlas parcellation. This is a useful document for making sense of the abbreviations provided in the ABCD imaging files. 

```{r, load in Excel spreadsheet with abbreviations and descriptions for brain regions}

brain_region_description <- read_excel("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/prep/brain_measures_descriptions.xlsx")

```
\#STEP 1: LOAD DATA FOR QUALITY CONTROL AND SELECT VALID IDS

\#USER: Adjust filter accordingly depending on your timepoint of interest (e.g., baseline, year 2 etc.)

For the purposes of this project, we are interested in Year 0 (baseline) and Year 2 (Two-year followup) Imaging data:

variable names: "baseline_year_1\_arm_1" and "2_year_follow_up_y\_arm_1"

Need satisfactory T1 raw images and DTI QC. Baseline and Year 2 will be run separately.

Note: Approximately 87% of participants completed year 2 neuroimaging due Covid-19 related data collection disruption.

See protocol notes: <https://abcdstudy.org/scientists/protocols>

```{r, load data and tidy}

qc_imgincl <-readRDS("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_QC/abcd_imgincl01.rds")

qc_imgincl$eventname <- as.factor(qc_imgincl$eventname) #check variable levels (needs to be in factor format)
levels(qc_imgincl$eventname)

#Check how sample sizes for each wave of imaging data. 
img_sample_siz_tbl <- qc_imgincl %>%
  group_by(eventname) %>% 
  summarise(no_rows = length(eventname))
print(img_sample_siz_tbl)

#Make separate dataframes for Baseline and Year 2

#Baseline (year 0) N= 11,801
qc_imgincl_y0 <- qc_imgincl %>% 
  filter(eventname == "baseline_year_1_arm_1") #reduce to year 0 data only, 

#Year 2 N= 7,857
qc_imgincl_y2 <- qc_imgincl %>% 
  filter(eventname == "2_year_follow_up_y_arm_1") 
```

Select IDs that passed QC for T1 (cortical and subcortical) and DTI

Field name: imgincl_t1w_include = T1: Number of series that are complete and passed QC. Valid IDs: =="yes"

Field name: imgincl_dmri_include = DTI: Number of series that are complete and passed QC. Valid IDs: =="yes"

```{r, valid IDs}

#here we simply create new values i.e. t1.ids.pass - if a subject id fulfills the criteria, it will pass into this new value. 

### Baseline ###

#T1 valid IDs
t1_ids_pass_y0 <- qc_imgincl_y0 %>% 
  select(src_subject_id, imgincl_t1w_include) %>%  
  filter(imgincl_t1w_include == "Yes") 
t1_ids_pass_y0 <- t1_ids_pass_y0$src_subject_id # make new column for valid t1 IDs --- N = 11,401

# DTI valid IDs
dti_ids_pass_y0 <- qc_imgincl_y0 %>% 
  select(src_subject_id,imgincl_dmri_include) %>% 
  filter(imgincl_dmri_include == "Yes")
dti_ids_pass_y0 <- dti_ids_pass_y0$src_subject_id #make new column for valid DTI IDs ---- N = 10,406


###Year 2 ###
# T1 valid IDs
t1_ids_pass_y2<- qc_imgincl_y2 %>% 
  select(src_subject_id, imgincl_t1w_include) %>%  
  filter(imgincl_t1w_include == "Yes") 
t1_ids_pass_y2 <- t1_ids_pass_y2$src_subject_id # make new column for valid t1 IDs --- N = 7,695


# DTI valid IDs
dti_ids_pass_y2 <- qc_imgincl_y2 %>% 
  select(src_subject_id,imgincl_dmri_include) %>% 
  filter(imgincl_dmri_include == "Yes")
dti_ids_pass_y2 <- dti_ids_pass_y2$src_subject_id #make new column for valid DTI IDs ---- N = 7,315

```

\#STEP 2: PROCESS IMAGING DATA

#### Cortical Measures

\#Using cortical volume, surface area, thickness and sulcal depth.

```{r, load T1 structural measures (cortical,subcortical) data}
t1 <- rio::import("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_T_roi/abcd_smrip10201.rds")

```

Rename columns to make more intuitive/easier to read

Note: APARC = cortical parcellation in Free Surfer syntax

```{r, rename columns}

colnames(t1)=gsub('smri_','',colnames(t1))
colnames(t1)=gsub('_cdk_','.APARC.',colnames(t1)) 
colnames(t1)=gsub('_scs_','.ASEG.',colnames(t1)) 
colnames(t1)=gsub('thick.','thk.',colnames(t1))
colnames(t1)=gsub('area.','sa.',colnames(t1))

```

\#Whole Brain Volume\#

We will use wholebrain volume (WBV) as a covariate in our regional measure models but not in our global measure models. ABCD have derived a measure of WBV that we will use but we will rename it to just "WBV". 

We are choosing to use WBV instead of intracranial volume to account for differences in overall brain size. According to previous research (e.g., Mills et al., 2016, https://www.sciencedirect.com/science/article/pii/S1053811916303512?via%3Dihub#bb0190), ICV and WBV demonstrate different growth trajectories and should not be used interchangeably. Further, WBV may be a more appropriate measure to use in developmental samples.  

```{r, change WBV variable name}

t1$WBV = t1$vvol.ASEG.wholeb #rename var
t1=t1[,!grepl('vol.ASEG.intracranialv',colnames(t1))] #remove old

```

Rearrange col names so that hemisphere (lh or rh or bl (bilateral) is indicated as the start of col name

```{r, further renaming}

colnames(t1)[grep('lh$',colnames(t1))]=paste0('lh.',gsub('lh$','',colnames(t1)))[grep('lh$',colnames(t1))]
colnames(t1)[grep('rh$',colnames(t1))]=paste0('rh.',gsub('rh$','',colnames(t1)))[grep('rh$',colnames(t1))]
colnames(t1)[grep('^vol.|^sa.|^sulc.|^thk.',colnames(t1))]=paste0('bl.',colnames(t1))[grep('^vol.|^sa.|^sulc.|^thk.',colnames(t1))]

colnames(t1) #check it worked

```

We will remove total and mean measures for each hemisphere (i.e., rh and lh) as we are not interested in these for the purposes of the present analysis.

This will leave us with cortical metrics (vol, sa, sulcal depth and thickness) for individual regions.

```{r, remove total and mean hemisphere measures}

cols_omit <-  t1 %>% .[grep(c("^rh.+\\.total$|^lh.+\\.total$|^rh.+\\.mean$|^lh.+\\.mean$"),colnames(.))] 
t1 <- t1[,!colnames(t1) %in% colnames(cols_omit)]

```

Generate separate dataframes for Baseline and Year 2 and extract variables of interest
Note: we are selecting our imaging columns that contain "APARC" as these are the Freesurfer derived metrics we are using. 
```{r, generate df and extract vars of interest}
### Baseline ###
cortical_y0 <- t1 %>% 
  filter(eventname == "baseline_year_1_arm_1") %>% #reduce to baseline; N= 11760
  select("src_subject_id", contains("APARC"), "ICV") #selecting cols contains "APARC" = 278 variables in df and also ICV
   

### Year 2 ###
cortical_y2 <- t1 %>%  
  filter(eventname == "2_year_follow_up_y_arm_1") %>% #reduce to Year 2 only --- N= 7827
  select("src_subject_id", contains("APARC"), "ICV") #select cols containing "APARC" = 278 vars

```

Select IDs that passed QC check ---- N=11232

Note: If the above QC steps have run correctly, the final N you get here should equal the N for t1_ids_pass_y0 etc.

```{r, select QC'd IDs}

### Baseline ###

cortical_y0_final <- cortical_y0 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y0,]  #N = 11401


### year 2 ###
cortical_y2_final <- cortical_y2 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y2,] #N= 7695
colnames(cortical_y2_final) #check col names 

```

Check distribution for global (total) vol and sa. Looks normally distributed so all good!

```{r, check distribution vol and sa}

### Baseline ###
cortical_y0_final %>%
  select(contains(".total")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 15) #Looks fine. 

### Year 2 ###
cortical_y2_final %>%
  select(contains(".total")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 15) #Looks fine. 


```

Check distribution for global (mean) sulc and thk. Looks okay too!

```{r, check distribution sulc and thk, fig.show="hold", out.width="50%"}

### Baseline ###
cortical_y0_final %>%
  select(contains(".mean")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4", 
                 bins = 15) 

### Year 2 ###
cortical_y2_final %>%
  select(contains(".mean")) %>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4", 
                 bins = 15) 

```

#### DTI/White matter Measures

Using fractional anisotropy and mean diffusivity as measures of white matter microstructure.

Note that we are using the inner shell DTI measures for this analysis (abcd_dti_p101.rds) instead of Full shell DTI measures (abcd_dmdtifp101.rds). Both measures are available in ABCD. We have conducted sensitivity analysis between the two measures and we found very similiar effects sizes across inner shell and full shell for DTI. 

There is some research suggesting that Full shell is more appropriate for developmental samples (e.g., https://www.sciencedirect.com/science/article/pii/S1878929320300360). However, given the results of the sensitivity analysis, for the present study (i.e., MacSweeney et al.'s RR), we will stick to inner shell. 

```{r, load DTI measures}
dti <- rio::import("/Volumes/GenScotDepression/data/abcd/release4.0/iii.data/MRI_T_roi/abcd_dti_p101.rds")

```

Tidy up column names

```{r, rename columns}

colnames(dti)[grep('\\.all&rh$',colnames(dti))]=
  paste0('rhtotal.',gsub('\\.all|rh$','',colnames(dti)))[grep('\\.all|rh$',colnames(dti))]

#rearrange col names as done for cortical measures to make reading easier. 
colnames(dti)[grep('lh$',colnames(dti))]=paste0('lh.',gsub('lh$','',colnames(dti)))[grep('lh$',colnames(dti))]
colnames(dti)[grep('rh$',colnames(dti))]=paste0('rh.',gsub('rh$','',colnames(dti)))[grep('rh$',colnames(dti))]
colnames(dti)[grep('\\_all',colnames(dti))]=paste0('bl.',colnames(dti))[grep('\\_all',colnames(dti))]
colnames(dti)[grep('^dti',colnames(dti))]=paste0('bl.',colnames(dti))[grep('^dti',colnames(dti))]

```
Here, we want to reduce the dataframes to our variables of interest. We want to keep all fa and md measures for our tracts of interest and exclude certain columns (detailed below) that are not relevant to our analysis. 

At this point we will generate separate dataframes for each timepoint (i.e., Baseline (Year 0) and Year 2)

```{r, reduce to variables of interest per timepoint}

### Baseline ###
dti_y0 <- dti %>% 
  filter(eventname == "baseline_year_1_arm_1") %>% 
  .[,grep("subject|_dtifa_|_dtimd_", colnames(.))] %>% #select FA and MD cols
  .[,grep('subject|fiberat',colnames(.))] #include DTI atlas tract adjustment #should have 85 variables 

#remove average FA and MD in tracts without corpus callosum (_allfcc) and the average longitudinal coefficient across all DTI tract fibers(_allfib)
cols.omit <- dti_y0 %>% .[grep("_allfcc$|_allfib$",colnames(.))] 
dti_y0 <- dti_y0[,!colnames(dti_y0) %in% colnames(cols.omit)] #should have 77 variables

#Tidy up column names
colnames(dti_y0)=gsub('dmri_','',colnames(dti_y0))
colnames(dti_y0)=gsub('fiberat_','',colnames(dti_y0))

### Year 2 ###
dti_y2 <- dti %>% 
  filter(eventname == "2_year_follow_up_y_arm_1") %>% 
  .[,grep("subject|_dtifa_|_dtimd_", colnames(.))] %>% #select FA and MD cols
  .[,grep('subject|fiberat',colnames(.))] #include DTI atlas tract adjustment #should have 85 variables 

#remove average FA and MD in tracts without corpus callosum (_allfcc) and the average longitudinal coefficient across all DTI tract fibers(_allfib)
cols.omit <- dti_y2 %>% .[grep("_allfcc$|_allfib$",colnames(.))] 
dti_y2 <- dti_y2[,!colnames(dti_y2) %in% colnames(cols.omit)] #should have 77 variables

#Tidy up column names
colnames(dti_y2)=gsub('dmri_','',colnames(dti_y2))
colnames(dti_y2)=gsub('fiberat_','',colnames(dti_y2))

```

Select IDs that pass QC for each timepoint

```{r, select valid IDs}

### Baseline ###
dti_y0_final<- dti_y0 %>% 
  .[.$src_subject_id %in% dti_ids_pass_y0,] #N= 10,406

### year 2 ###
dti_y2_final<- dti_y2 %>% 
  .[.$src_subject_id %in% dti_ids_pass_y2,] #N= 7,315


```

Check distribution of FA and MD

The MD values do appear to be skewed. However, instead of removing outliers at this stage, we can conduct a sensitivity analysis at a later stage (if needed) to see if the outliers are affecting the associations. However, removing outliers ±5 SD does not seem to be the standard approach taken by other ABCD users. It is important to note that the ABCD team remove impossible values in advance of the curated data release and therefore, the extreme values are likely real.

```{r, check distribution, fig.show="hold", out.width="50%"}
###Baseline###
dti_y0_dist <- dti_y0_final %>%
  select(ends_with("allfibers"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) 
dti_y0_dist

###year 2###
dti_y2_dist <- dti_y2_final %>%
  select(ends_with("allfibers"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins = 30) 
dti_y2_dist
```
\#\#\#\#Subcortical volume measures (before QC, N =11,736)

We will select the subcortical regions that overlap with ENIGMA and add in the ventral diencephalon. Note that we are only looking at subcortical volume (not thicnkess, surface area or sulcal depth)

We have already renamed and tidied to T1 file above so we can load this in from our global environment and then select the subcortical variables and ICV. 
```{r, make subcortical df from t1}

subcort <- t1 

```

Create separate dataframes for Baseline and Year 2.

```{r, make DFs for baseline and year 2}

###Baseline####
subcort_y0 <- subcort %>% 
filter(eventname == "baseline_year_1_arm_1") %>% #reduce to baseline --- N = 11,760
.[,grep("subject|vol.ASEG.|ICV", colnames(.))] %>%   #select smri vol data
.[,grep("subject|aa|amygdala|caudate|hpus|pallidum|putamen|tp|vedc|cranial|subcortical|ICV",colnames(.))] #select relevant columns 

###Year 2 ####
subcort_y2 <- subcort %>% 
filter(eventname == "2_year_follow_up_y_arm_1") %>% #reduce to  --- N = 7827
.[,grep("subject|vol.ASEG.|ICV", colnames(.))] %>%   #select smri vol data
.[,grep("subject|aa|amygdala|caudate|hpus|pallidum|putamen|tp|vedc|cranial|subcortical|ICV",colnames(.))] #select relevant columns


```

Select IDs that passed QC, N=11,232

```{r, select valid IDs}

###Baseline####
subcort_y0_final <- subcort_y0 %>% 
  .[.$src_subject_id %in% t1_ids_pass_y0,] #N= 11401


subcort_y2_final <- subcort_y2 %>% 
   .[.$src_subject_id %in% t1_ids_pass_y2,] #N= 7695


```

Check distribution of subcortical measures

```{r, check distribution, fig.show="hold", out.width="50%"}

###Baseline####
 subcort_y0_dist <- subcort_y0_final %>%
  select(!starts_with("src"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) #all look okay
subcort_y0_dist

###Year 2####
 subcort_y2_dist <- subcort_y2_final %>%
  select(!starts_with("src"))%>% 
  gather() %>% 
  ggplot(aes(as.numeric(value)))+
  facet_wrap(~ key, scales = "free") +
  geom_histogram(fill = "deepskyblue4",
                 bins =30) #all look okay
 subcort_y2_dist
```
Let's look at the final variables for subcortical measures (17 in total, including lh and rh) after QC. Note: subcortical_gv = subcortical grey volume.


####EXPORT CLEANED DATA

USER: change as needed 

Change working directory and save clean file there. Note: clean files should be saved in data folder in ABCD_puberty_RR project folder.

```{r, export cleaned data}

setwd("/Volumes/GenScotDepression/users/niamh/puberty_ABCD/ABCD_puberty_depression/data")

###Baseline data ####
saveRDS(cortical_y0_final,"cortical_baseline_R4.0.rds")
saveRDS(dti_y0_final,"dti_baseline_R4.0.rds")
saveRDS(subcort_y0_final,"subcort_baseline_R4.0.rds")

###Year 2 data ####
saveRDS(cortical_y2_final,"cortical_year2_R4.0.rds")
saveRDS(dti_y2_final,"dti_year2_R4.0.rds")
saveRDS(subcort_y2_final,"subcort_year2_R4.0.rds")

```

\#\#\#\#------------ END OF MAIN SCRIPT -----------------\#\#\#\#
